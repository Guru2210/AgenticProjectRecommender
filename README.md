# CV Project Recommender ğŸ¯

A production-ready agentic AI system that analyzes CVs against job descriptions, identifies skill gaps, and recommends tailored projects with learning resources.

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![LangGraph](https://img.shields.io/badge/LangGraph-latest-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-latest-red.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

## âœ¨ Features

### Frontend (Streamlit)
- **ğŸ“„ Intelligent CV Parsing**: Automatically extracts skills, experience, education, and certifications from PDF/DOCX files
- **ğŸ¯ Job Analysis**: Analyzes job descriptions and categorizes required vs. preferred skills
- **ğŸ“Š Skill Gap Analysis**: Identifies missing skills with fuzzy matching and prioritization
- **ğŸ’¡ Project Recommendations**: Generates tailored project ideas for each skill gap (beginner to advanced)
- **ğŸ” Resource Discovery**: Finds relevant GitHub repositories and YouTube tutorials
- **ğŸ—ºï¸ Learning Paths**: Creates personalized roadmaps for skill acquisition
- **ğŸ“ˆ Visual Analytics**: Interactive charts and progress tracking

### Backend (FastAPI)
- **ğŸš€ REST API**: Complete API for CV analysis with async processing
- **âš¡ Background Tasks**: Celery-based task queue for long-running operations
- **ğŸ”„ Real-time Updates**: WebSocket support for live progress tracking
- **ğŸ“¡ Job Management**: Submit, track, and retrieve analysis results
- **ğŸ“š API Documentation**: Auto-generated Swagger/ReDoc documentation
- **ğŸ³ Docker Ready**: Multi-service containerized deployment

### Production Features
- **ğŸ“ Structured Logging**: JSON logs with rotation
- **ğŸ’¾ Caching**: Redis-based caching with TTL
- **â±ï¸ Rate Limiting**: Token bucket algorithm per API
- **ğŸ›¡ï¸ Error Handling**: Comprehensive error recovery
- **ğŸ“Š Monitoring**: Celery Flower for task monitoring

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit UI   â”‚         â”‚   Other Clients  â”‚
â”‚   (Port 8501)   â”‚         â”‚  (Mobile/React)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   FastAPI Backend      â”‚
         â”‚     (Port 8000)        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Celery Worker        â”‚
         â”‚  (Background Tasks)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                â”‚                â”‚
    â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redis  â”‚    â”‚   LLM    â”‚    â”‚ External â”‚
â”‚ Cache  â”‚    â”‚ (OpenAI) â”‚    â”‚   APIs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚            â”‚            â”‚
                    â–¼            â–¼            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ GitHub  â”‚  â”‚ YouTube â”‚  â”‚  Other  â”‚
              â”‚   API   â”‚  â”‚   API   â”‚  â”‚   ...   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```mermaid
graph LR
    A[CV Upload] --> B[CV Parser Agent]
    C[Job Description] --> D[Job Analyzer Agent]
    B --> E[Skill Gap Analyzer Agent]
    D --> E
    E --> F[Project Recommender Agent]
    F --> G[GitHub Search]
    F --> H[YouTube Search]
    F --> I[LLM Project Generator]
    G --> J[Results]
    H --> J
    I --> J
```

### Agent Responsibilities

1. **CV Parser Agent**: Extracts structured data from CV documents using LLM
2. **Job Analyzer Agent**: Parses job descriptions and categorizes requirements
3. **Skill Gap Analyzer Agent**: Compares skills and identifies gaps with fuzzy matching
4. **Project Recommender Agent**: Generates projects and finds learning resources

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- OpenAI API key (required)
- GitHub Personal Access Token (optional, for better rate limits)
- YouTube Data API key (required)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd AgenticProjectRecommender
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` and add your API keys:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   GITHUB_TOKEN=your_github_token_here
   YOUTUBE_API_KEY=your_youtube_api_key_here
   ```

5. **Run the application**
   ```bash
   streamlit run app.py
   ```

6. **Open your browser**
   Navigate to `http://localhost:8501`

## ğŸ³ Docker Deployment

### Using Docker Compose (Recommended)

```bash
# Build and start services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

The application will be available at `http://localhost:8501`

## ğŸš€ Running with FastAPI Backend

### Using Docker Compose (All Services)

```bash
# Start all services (Backend, Celery, Flower, Streamlit, Redis)
docker-compose up -d

# View logs
docker-compose logs -f

# Stop all services
docker-compose down
```

**Services:**
- **FastAPI Backend**: http://localhost:8000
- **API Documentation**: http://localhost:8000/api/docs
- **Celery Flower**: http://localhost:5555 (task monitoring)
- **Streamlit UI**: http://localhost:8501
- **Redis**: localhost:6379

### Running Locally (Development)

You'll need to run multiple services:

**Terminal 1 - Redis:**
```bash
redis-server
```

**Terminal 2 - Celery Worker:**
```bash
celery -A backend.tasks worker --loglevel=info
```

**Terminal 3 - FastAPI Backend:**
```bash
uvicorn backend.main:app --reload --port 8000
```

**Terminal 4 - Streamlit (Optional):**
```bash
streamlit run app.py
```

**Terminal 5 - Flower (Optional):**
```bash
celery -A backend.tasks flower --port=5555
```

## ğŸ“¡ Using the API

### Quick API Example

```python
import requests

# 1. Submit CV for analysis
with open('cv.pdf', 'rb') as cv_file:
    response = requests.post(
        'http://localhost:8000/api/analyze',
        data={'job_description': 'Senior Developer with Python...'},
        files={'cv_file': cv_file}
    )

job_id = response.json()['job_id']

# 2. Check status
status = requests.get(f'http://localhost:8000/api/status/{job_id}').json()
print(f"Progress: {status['progress_percentage']}%")

# 3. Get results (when completed)
results = requests.get(f'http://localhost:8000/api/results/{job_id}').json()
print(f"Match: {results['result']['skill_match_analysis']['match_percentage']}%")
```

### API Endpoints

- `GET /api/health` - Health check
- `POST /api/analyze` - Submit CV for analysis
- `GET /api/status/{job_id}` - Check job status
- `GET /api/results/{job_id}` - Get analysis results
- `WebSocket /api/ws/{job_id}` - Real-time progress updates

See [API Documentation](docs/API.md) for complete details.

### Using the Python Client

```python
from examples.api_client import CVRecommenderClient

client = CVRecommenderClient("http://localhost:8000")

# Analyze and wait for results
results = client.analyze_and_wait(
    job_description="...",
    cv_file_path="cv.pdf",
    callback=lambda s: print(f"{s['progress_percentage']}%")
)
```

### Using Docker Only

```bash
# Build image
docker build -t cv-recommender .

# Run container
docker run -p 8501:8501 --env-file .env cv-recommender
```

## ğŸ“– Usage Guide

### 1. Upload Your CV
- Supported formats: PDF, DOCX
- Ensure your CV includes skills, experience, education, and certifications

### 2. Paste Job Description
- Copy the complete job posting
- Include requirements, responsibilities, and qualifications

### 3. Analyze
- Click "Analyze & Generate Recommendations"
- Wait 30-60 seconds for processing

### 4. Review Results
- **Skill Match Analysis**: Visual breakdown of your match percentage
- **Skill Gaps**: Prioritized list of missing skills
- **Project Recommendations**: 3 projects per skill (beginner, intermediate, advanced)
- **Learning Resources**: Curated GitHub repos and YouTube tutorials
- **Learning Paths**: Step-by-step roadmaps

### 5. Export
- Download results as JSON for future reference

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENAI_API_KEY` | Yes | OpenAI API key for LLM |
| `OPENAI_MODEL` | No | Model to use (default: gpt-4-turbo-preview) |
| `GITHUB_TOKEN` | No | GitHub PAT for higher rate limits |
| `YOUTUBE_API_KEY` | Yes | YouTube Data API v3 key |
| `LOG_LEVEL` | No | Logging level (default: INFO) |
| `CACHE_ENABLED` | No | Enable caching (default: true) |
| `REDIS_HOST` | No | Redis host (default: localhost) |

### API Rate Limits

- **GitHub**: 60 req/hour (unauthenticated), 5000 req/hour (authenticated)
- **YouTube**: 10,000 quota units/day
- **OpenAI**: Depends on your plan

The system implements intelligent caching and rate limiting to stay within these bounds.

## ğŸ“ Project Structure

```
AgenticProjectRecommender/
â”œâ”€â”€ agents/                 # Agent implementations
â”‚   â”œâ”€â”€ cv_parser.py
â”‚   â”œâ”€â”€ job_analyzer.py
â”‚   â”œâ”€â”€ skill_gap_analyzer.py
â”‚   â””â”€â”€ project_recommender.py
â”œâ”€â”€ backend/                # FastAPI backend
â”‚   â”œâ”€â”€ main.py            # FastAPI application
â”‚   â”œâ”€â”€ schemas.py         # Request/response models
â”‚   â””â”€â”€ tasks.py           # Celery background tasks
â”œâ”€â”€ graph/                  # LangGraph orchestration
â”‚   â”œâ”€â”€ state.py
â”‚   â”œâ”€â”€ nodes.py
â”‚   â””â”€â”€ workflow.py
â”œâ”€â”€ integrations/           # External API clients
â”‚   â”œâ”€â”€ github_search.py
â”‚   â”œâ”€â”€ youtube_search.py
â”‚   â””â”€â”€ llm_client.py
â”œâ”€â”€ models/                 # Pydantic data models
â”‚   â”œâ”€â”€ cv_models.py
â”‚   â”œâ”€â”€ job_models.py
â”‚   â””â”€â”€ recommendation_models.py
â”œâ”€â”€ ui/                     # Streamlit components
â”‚   â””â”€â”€ components.py
â”œâ”€â”€ utils/                  # Utilities
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ cache.py
â”‚   â”œâ”€â”€ rate_limiter.py
â”‚   â””â”€â”€ error_handler.py
â”œâ”€â”€ docs/                   # Documentation
â”‚   â””â”€â”€ API.md             # API documentation
â”œâ”€â”€ examples/               # Usage examples
â”‚   â””â”€â”€ api_client.py      # Python API client
â”œâ”€â”€ tests/                  # Tests
â”‚   â””â”€â”€ test_agents.py
â”œâ”€â”€ app.py                  # Streamlit app
â”œâ”€â”€ config.py               # Configuration
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ Dockerfile              # Docker config
â”œâ”€â”€ docker-compose.yml      # Multi-service setup
â””â”€â”€ README.md              # This file
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test file
pytest tests/test_agents.py
```

## ğŸ”’ Security Notes

- Never commit your `.env` file
- Use environment variables for all API keys
- Rotate API keys regularly
- Use GitHub tokens with minimal required scopes

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- **LangGraph** for agent orchestration
- **LangChain** for LLM integration
- **Streamlit** for the web interface
- **OpenAI** for GPT models

## ğŸ“§ Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check the FAQ in the app's Instructions tab

## ğŸ—ºï¸ Roadmap

- [ ] Support for more CV formats (LinkedIn PDF, plain text)
- [ ] Multi-language support
- [ ] Integration with job boards (LinkedIn, Indeed)
- [ ] Skill assessment quizzes
- [ ] Progress tracking dashboard
- [ ] Community project sharing

---

**Built with â¤ï¸ using LangGraph and Streamlit**
